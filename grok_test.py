#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ Grok-1 –æ—Ç xAI
–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å —Å Hugging Face –∏ —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –µ—ë —Å –ø—Ä–æ–º–ø—Ç–æ–º
"""

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
import warnings
import sys
import os

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
warnings.filterwarnings("ignore")

class GrokTester:
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_name = "hpcai-tech/grok-1"

    def check_system_requirements(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π"""
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π...")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
        if not torch.cuda.is_available():
            print("‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ú–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ)")
            print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU —Å –º–∏–Ω–∏–º—É–º 16GB VRAM")
            response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ")
            if response.lower() != 'y':
                sys.exit(0)
        else:
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            print(f"‚úÖ GPU –Ω–∞–π–¥–µ–Ω: {torch.cuda.get_device_name(0)}")
            print(f"   –ü–∞–º—è—Ç—å GPU: {gpu_memory:.1f} GB")

            if gpu_memory < 16:
                print("‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: GPU –ø–∞–º—è—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π –¥–ª—è Grok-1")
                print("   –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –º–∏–Ω–∏–º—É–º 16GB VRAM –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
        statvfs = os.statvfs('.')
        free_space = statvfs.f_frsize * statvfs.f_bavail / (1024**3)
        print(f"üíæ –°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: {free_space:.1f} GB")

        if free_space < 50:
            print("‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ")
            print("   –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –æ–∫–æ–ª–æ 314GB –º–µ—Å—Ç–∞")

    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞"""
        try:
            print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è {self.model_name}...")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )

            print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {self.model_name}...")
            print("   ‚è≥ –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è (–º–æ–¥–µ–ª—å –≤–µ—Å–∏—Ç ~314GB)...")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
            torch.set_default_dtype(torch.bfloat16)
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )

            if self.device == "cpu" and torch.cuda.is_available():
                print("   üîÑ –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU...")
                self.model = self.model.to(self.device)

            self.model.eval()
            print("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            print("\nüí° –í–æ–∑–º–æ–∂–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è:")
            print("   1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
            print("   2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ RAM/GPU –ø–∞–º—è—Ç–∏")
            print("   3. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç")
            sys.exit(1)

    def generate_response(self, prompt, max_length=200, temperature=0.7):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –ø—Ä–æ–º–ø—Ç"""
        try:
            print(f"\nü§ñ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–∞: '{prompt}'")
            print("   ‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")

            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
            input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids
            input_ids = input_ids.to(self.device)
            attention_mask = torch.ones_like(input_ids)

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            inputs = {
                "input_ids": input_ids,
                "attention_mask": attention_mask,
                "max_length": max_length,
                "temperature": temperature,
                "do_sample": True,
                "pad_token_id": self.tokenizer.eos_token_id,
                "top_p": 0.9,
                "top_k": 50
            }

            with torch.no_grad():
                outputs = self.model.generate(**inputs)

            # –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

            # –£–±–∏—Ä–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞
            if response.startswith(prompt):
                response = response[len(prompt):].strip()

            return response

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}")
            return None

    def run_tests(self):
        """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–∏–∏ —Ç–µ—Å—Ç–æ–≤"""
        test_prompts = [
            "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?",
            "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ñ–∏–∑–∏–∫—É –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏",
            "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏",
            "–ö–∞–∫–æ–≤—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è?"
        ]

        print("\nüß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤...")
        print("=" * 60)

        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nüìù –¢–µ—Å—Ç {i}/{len(test_prompts)}")
            response = self.generate_response(prompt)

            if response:
                print(f"‚ùì –ü—Ä–æ–º–ø—Ç: {prompt}")
                print(f"ü§ñ –û—Ç–≤–µ—Ç: {response}")
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –¥–ª—è: {prompt}")

            print("-" * 40)

    def interactive_mode(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤"""
        print("\nüí¨ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º (–≤–≤–µ–¥–∏—Ç–µ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞)")
        print("=" * 50)

        while True:
            try:
                prompt = input("\nüìù –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –ø—Ä–æ–º–ø—Ç: ")

                if prompt.lower() in ['quit', 'exit', '–≤—ã—Ö–æ–¥']:
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break

                if not prompt.strip():
                    continue

                response = self.generate_response(prompt)

                if response:
                    print(f"ü§ñ Grok-1: {response}")
                else:
                    print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç")

            except KeyboardInterrupt:
                print("\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                break
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ Grok-1 –¢–µ—Å—Ç–µ—Ä v1.0")
    print("=" * 40)

    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Ç–µ—Å—Ç–µ—Ä–∞
    tester = GrokTester()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
    tester.check_system_requirements()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    tester.load_model()

    # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    print("\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
    print("1. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã")
    print("2. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º")
    print("3. –û–±–∞ —Ä–µ–∂–∏–º–∞")

    try:
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3): ").strip()

        if choice == "1":
            tester.run_tests()
        elif choice == "2":
            tester.interactive_mode()
        elif choice == "3":
            tester.run_tests()
            tester.interactive_mode()
        else:
            print("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
